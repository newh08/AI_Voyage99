
### 기본과제 기록 (val test 기준)
1. AutoModelForSequenceClassification 모델을 Distilbert 로 불러 사용, lr= 1e-5, 파라미터 고정 해제 -> 정확도 0.503
2. 동일 조건에 파라미터만 고정해봤다. SequenceClassification 모델이니 사전학습 파라미터가 더 의미 있을거라 판단했지만, -> 정확도 0.376
3. 파라미터 고정은 해제하고 lr 을 5e-5 로 조금 더 높였다 -> 정확도 0.512 / 그런데 3에폭시 이후엔 오버피팅이 발생한것 같다.
4. 학습 데이터가 적어서 오버피팅 발생? 학습 데이터를 늘려서 3번 모델로 진행하기 -> 1에폭시의 정확도 대폭 상승, 그러나 여전히 3에폭시 이후엔 오버피팅 발생
5. 전체 데이터셋을 사용해 3번 모델에 1에폭시만 학습하기 -> 정확도 대폭 상승


- HuggingFace 에서 제공하는 다양한 함수들
	- map() : 데이터를 토큰화 할 때 사용
   	- train_test_split() : train 데이터에서 val 데이터를 분리할 때 사용
   	- TrainingArguments : 학습 위한 컨피그. 다양한 파라미터 있음.
   	- evaluate.load() : 평가 함수 불러올수 있음


### 기본과제 에러 발생 상황
1. 토크나이저(Bert)와 모델(distilBert)을 다른 종류로 불러왔다.
	- Bert 토크나이저는 `token_type_ids` 를 만들지만, distillBert 는 이걸 사용하지 않는다.
	- 학습시엔 이런 값을 무시하고 진행할 수 있었지만, 평가 단계에선 모든 입력이 GPU 로 전송되기 때문에 런타임 에러가 발생한다.
2. test 데이터에서 라벨이 전부 -1 이었다.
	- 데이터 사용하기 전에 한번 더 확인해보는 작업이 필요할 것 같다.
